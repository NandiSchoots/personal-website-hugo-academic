---
bio: ""
interests:
  - Science of Deep Learning
  - and (Implicit) Inductive Biases in Neural Networks
  - Machine Unlearning and Activation Steering
  - Societal Impacts of AI and AI Safe
organizations: []
education:
  - area: PhD Artificial Intelligence
    institution: Stanford University
    date_start: 2016-01-01
    date_end: 2020-12-31
    summary: >
      Thesis on _Why LLMs are awesome_. Supervised by [Prof Joe
      Smith](https://example.com). Presented papers at 5 IEEE conferences with
      the contributions being published in 2 Springer journals.
    button:
      text: Read Thesis
      url: https://example.com
  - area: MEng Artificial Intelligence
    institution: Massachusetts Institute of Technology
    date_start: 2016-01-01
    date_end: 2020-12-31
    summary: |
      GPA: 3.8/4.0

      Courses included:
      - lorem ipsum dolor sit amet, consectetur adipiscing elit
      - lorem ipsum dolor sit amet, consectetur adipiscing elit
      - lorem ipsum dolor sit amet, consectetur adipiscing elit
  - area: BSc Artificial Intelligence
    institution: Massachusetts Institute of Technology
    date_start: 2016-01-01
    date_end: 2020-12-31
    summary: |
      GPA: 3.4/4.0

      Courses included:
      - lorem ipsum dolor sit amet, consectetur adipiscing elit
      - lorem ipsum dolor sit amet, consectetur adipiscing elit
      - lorem ipsum dolor sit amet, consectetur adipiscing elit
superuser: true
profiles:
  - icon: at-symbol
    url: mailto:nandischoots@gmail.com
    label: E-mail Me
  - icon: brands/github
    url: https://github.com/NandiSchoots
  - icon: academicons/google-scholar
    url: https://scholar.google.com/citations?hl=en&user=wO7fg6wAAAAJ
  - icon: brands/x
    url: https://twitter.com/NandiSchoots
avatar_filename: profile-picture.jpg
status:
  icon: ☕️
last_name: Schoots
role: ""
highlight_name: true
title: Nandi Schoots
first_name: Nandi
---
## About Me

I'm searching for research questions that cut to the core of human understanding and hope to one day find natural laws that make highly specific predictions and apply in many contexts. In the mean-time I'm working on a variety of projects that piqued my interest.

I am an [FLI](<https://futureoflife.org/grant-program/postdoctoral-fellowships/ >) postdoctoral researcher in Alessandro Abate’s [OXCAV](https://oxcav.web.ox.ac.uk/) group at the University of Oxford. Previously, I did my PhD in the [STAI](https://safeandtrustedai.org/) group under supervision of Peter McBurney (King’s College London) and Murray Shanahan (Imperial College London, DeepMind). 

I was one of the main organizers of the first [AI Safety Camp](https://aisafety.camp/).
