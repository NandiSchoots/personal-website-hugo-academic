---
bio: ""
interests:
  - Science of Deep Learning and (Implicit) Inductive Biases in Neural Networks
  - Machine Unlearning and Activation Steering
  - Societal Impacts of AI and AI Safe
organizations: []
superuser: true
profiles:
  - icon: at-symbol
    url: mailto:nandischoots@gmail.com
    label: E-mail Me
  - icon: brands/github
    url: https://github.com/NandiSchoots
  - icon: academicons/google-scholar
    url: https://scholar.google.com/citations?hl=en&user=wO7fg6wAAAAJ
  - icon: brands/x
    url: https://twitter.com/NandiSchoots
avatar_filename: profile-picture.jpg
status:
  icon: 
last_name: Schoots
role: ""
highlight_name: true
title: Nandi Schoots
first_name: Nandi
---
## About Me

I'm searching for research questions that cut to the core of human understanding and hope to one day find natural laws that make highly specific predictions and apply in many contexts. In the mean-time I'm working on a variety of projects that piqued my interest.

I am an [FLI](<https://futureoflife.org/grant-program/postdoctoral-fellowships/ >) postdoctoral researcher in Alessandro Abate’s [OXCAV](https://oxcav.web.ox.ac.uk/) group at the University of Oxford. Previously, I did my PhD in the [STAI](https://safeandtrustedai.org/) group under supervision of Peter McBurney (King’s College London) and Murray Shanahan (Imperial College London, DeepMind). 

I was one of the main organizers of the first [AI Safety Camp](https://aisafety.camp/).
